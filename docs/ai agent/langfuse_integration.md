# Langfuse Integration

LLM Observability for the AI Agent System.

## What is Langfuse?

[Langfuse](https://langfuse.com) is an open-source LLM observability platform that tracks:
- **Token usage** (input/output per call)
- **Cost** (USD per request/session)
- **Latency** (response times)
- **Traces** (full agent execution flow)
- **Errors** (failures, rate limits)

## Architecture

```
┌─────────────────────────────────────────────────────────────┐
│                    AI Agent System                          │
│  ┌─────────┐  ┌──────────┐  ┌──────────┐  ┌───────────┐    │
│  │Explorer │  │ Builder  │  │ Executor │  │  Analyst  │    │
│  └────┬────┘  └────┬─────┘  └────┬─────┘  └─────┬─────┘    │
│       │            │             │              │           │
│       └────────────┴──────┬──────┴──────────────┘           │
│                           │                                 │
│                    ┌──────▼──────┐                          │
│                    │  Langfuse   │                          │
│                    │   Wrapper   │                          │
│                    └──────┬──────┘                          │
└───────────────────────────┼─────────────────────────────────┘
                            │
                    ┌───────▼───────┐
                    │   Langfuse    │
                    │   Dashboard   │
                    │  (port 3001)  │
                    └───────────────┘
```

## Setup Options

### Option 1: Self-Hosted (Free, Recommended)

Run Langfuse on your infrastructure. No data leaves your servers.

```bash
# Run the install script
./scripts/langfuse_install.sh
```

Access dashboard at: `http://localhost:3001`

### Option 2: Cloud (Quick Start)

1. Sign up at [cloud.langfuse.com](https://cloud.langfuse.com)
2. Get your API keys from the dashboard
3. Configure `.env`:

```bash
LANGFUSE_ENABLED=true
LANGFUSE_PUBLIC_KEY=pk-lf-...
LANGFUSE_SECRET_KEY=sk-lf-...
LANGFUSE_HOST=https://cloud.langfuse.com
```

## Configuration

### Environment Variables

Add to `backend_server/.env`:

```bash
# Langfuse LLM Observability (Optional)
# Set to true to enable token/cost tracking
LANGFUSE_ENABLED=false

# Self-hosted (after running langfuse_install.sh)
LANGFUSE_HOST=http://localhost:3001
LANGFUSE_PUBLIC_KEY=pk-lf-your-public-key
LANGFUSE_SECRET_KEY=sk-lf-your-secret-key

# Cloud (alternative)
# LANGFUSE_HOST=https://cloud.langfuse.com
# LANGFUSE_PUBLIC_KEY=pk-lf-...
# LANGFUSE_SECRET_KEY=sk-lf-...
```

### Enable/Disable

Toggle observability without code changes:

```bash
# Enable
LANGFUSE_ENABLED=true

# Disable (default)
LANGFUSE_ENABLED=false
```

When disabled, the system works normally without any Langfuse overhead.

## What Gets Tracked

| Metric | Description |
|--------|-------------|
| `input_tokens` | Tokens sent to Claude |
| `output_tokens` | Tokens generated by Claude |
| `cache_read_tokens` | Tokens read from prompt cache (90% cheaper) |
| `cache_create_tokens` | Tokens written to prompt cache |
| `duration_ms` | Response latency |
| `cost_usd` | Estimated cost per call |
| `agent_name` | Which agent made the call (Explorer, Builder, etc.) |
| `session_id` | Conversation session ID |
| `user_id` | User who initiated the request |

## Dashboard Features

Once enabled, access the Langfuse dashboard to see:

### Traces View
Full execution traces showing:
- QA Manager → Explorer → Builder flow
- Each tool call and result
- Token usage per step

### Analytics
- Daily/weekly token usage
- Cost breakdown by agent
- Latency percentiles
- Error rates

### Sessions
- Group traces by conversation
- See total cost per user session
- Identify expensive operations

## Pricing Comparison

| Setup | Monthly Cost | Data Location |
|-------|--------------|---------------|
| Self-hosted | **$0** | Your servers |
| Cloud Free | $0 (50k events) | Langfuse servers |
| Cloud Pro | $59+ | Langfuse servers |

## Troubleshooting

### Langfuse Not Connecting

```bash
# Check if Langfuse is running
docker ps | grep langfuse

# Check logs
docker logs langfuse-web-1

# Verify environment
echo $LANGFUSE_HOST
```

### No Data Showing

1. Verify `LANGFUSE_ENABLED=true`
2. Check API keys are correct
3. Make an AI Agent request
4. Wait 10-30 seconds for data to appear

### Port Conflict

If port 3001 is in use:

```bash
# Edit docker-compose.yml
# Change "3001:3000" to "3002:3000"
# Then access at http://localhost:3002
```

## Security

- Self-hosted: All data stays on your infrastructure
- API keys: Store in `.env`, never commit to git
- Network: Langfuse only needs outbound to your Anthropic calls

## Related

- [AI Agent Architecture](./ai_agentic.md)
- [Grafana Integration](/docs/integrations/grafana.md)

