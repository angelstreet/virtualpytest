# AI Centralization Architecture Plan - MINIMALIST

## ğŸ¯ **Objective**
Centralize AI inference with minimal code changes. Focus on centralizing models, providers, and core inference logic while keeping prompts where they make sense.

## ğŸ“Š **Current State Analysis**

### **Current Scattered Architecture (BEFORE)**

```
virtualpytest/
â”œâ”€â”€ backend_host/src/controllers/
â”‚   â”œâ”€â”€ ai/ai_agent.py                     # âŒ Direct OpenRouter, hardcoded model
â”‚   â””â”€â”€ verification/video_ai_helpers.py   # âŒ Direct OpenRouter, hardcoded model
â”œâ”€â”€ shared/lib/utils/
â”‚   â”œâ”€â”€ ai_utils.py                        # âŒ Basic utils, only OpenRouter
â”‚   â”œâ”€â”€ translation_utils.py               # âŒ Direct AI calls
â”‚   â””â”€â”€ browseruse_utils.py                # âŒ Different provider
â””â”€â”€ backend_discard/src/ai_analyzer.py     # âŒ Separate implementation
```

### **Current Problems**
- âŒ **Scattered API Calls**: 5+ files making direct AI API calls
- âŒ **Hardcoded Models**: Models scattered across files
- âŒ **No Provider Choice**: Only OpenRouter, no Hugging Face
- âŒ **Duplicate Code**: Same API patterns repeated
- âŒ **No Fallback**: Limited error handling between providers

## ğŸ—ï¸ **New Minimalist Architecture (AFTER)**

### **Simple File Structure - Only 3 New Files**

```
virtualpytest/
â”œâ”€â”€ shared/lib/ai/                         # ğŸ†• ONLY 3 FILES
â”‚   â”œâ”€â”€ __init__.py                        # ğŸ†• Simple exports
â”‚   â”œâ”€â”€ ai_service.py                      # ğŸ†• Main service (replaces scattered calls)
â”‚   â””â”€â”€ prompts.py                         # ğŸ†• Shared prompts only
â”œâ”€â”€ shared/lib/utils/
â”‚   â””â”€â”€ ai_utils.py                        # âœ… ENHANCED: Uses ai_service
â”œâ”€â”€ backend_host/src/controllers/
â”‚   â”œâ”€â”€ ai/ai_agent.py                     # âœ… MINIMAL CHANGE: Uses ai_service
â”‚   â””â”€â”€ verification/video_ai_helpers.py   # âœ… MINIMAL CHANGE: Uses ai_service
â””â”€â”€ config/ai_config.py                    # ğŸ†• Simple Python config (not YAML)
```

## ğŸ”§ **Minimalist Components**

### **1. Simple AI Service (One File)**
```python
# shared/lib/ai/ai_service.py
class AIService:
    """Simple centralized AI service - no over-engineering"""
    
    def __init__(self):
        self.providers = {
            'openrouter': self._openrouter_call,
            'huggingface': self._huggingface_call
        }
        self.default_provider = 'openrouter'
        self.fallback_provider = 'huggingface'
    
    # Main methods - same interface for all AI calls
    def call_ai(self, prompt, task_type='text', image=None, provider=None, **kwargs):
        """Single method for all AI calls"""
        
    def _openrouter_call(self, prompt, model, image=None, **kwargs):
        """OpenRouter implementation"""
        
    def _huggingface_call(self, prompt, model, image=None, **kwargs):
        """Hugging Face implementation"""
```

### **2. Simple Configuration**
```python
# config/ai_config.py
AI_CONFIG = {
    'providers': {
        'openrouter': {
            'api_key_env': 'OPENROUTER_API_KEY',
            'base_url': 'https://openrouter.ai/api/v1/chat/completions',
            'models': {
                'text': 'microsoft/phi-3-mini-128k-instruct',
                'vision': 'qwen/qwen-2.5-vl-7b-instruct',
                'translation': 'microsoft/phi-3-mini-128k-instruct'
            }
        },
        'huggingface': {
            'api_key_env': 'HUGGINGFACE_API_KEY',
            'base_url': 'https://api-inference.huggingface.co/models',
            'models': {
                'text': 'microsoft/DialoGPT-medium',
                'vision': 'Salesforce/blip-image-captioning-base',
                'translation': 'Helsinki-NLP/opus-mt-en-de'
            }
        }
    },
    'defaults': {
        'primary_provider': 'openrouter',
        'fallback_provider': 'huggingface',
        'timeout': 60,
        'max_tokens': 1000
    }
}
```

### **3. Shared Prompts (Optional)**
```python
# shared/lib/ai/prompts.py
SHARED_PROMPTS = {
    'json_response': "CRITICAL: Respond with ONLY valid JSON. No other text.",
    'language_menu': "Analyze this image for language/subtitle menu options...",
    'channel_banner': "Analyze this TV screen for channel information banner..."
}
```

## ğŸ”„ **Simple Migration - 3 Steps Only**

### **Step 1: Create AI Service (15 minutes)**
1. Create `shared/lib/ai/ai_service.py` - one file with both providers
2. Create `config/ai_config.py` - simple Python dict
3. Create `shared/lib/ai/__init__.py` - export AIService

### **Step 2: Update Existing Files (10 minutes each)**
1. Update `ai_utils.py` - replace direct calls with AIService
2. Update `ai_agent.py` - change import, same interface
3. Update `video_ai_helpers.py` - change import, same interface
4. Update `translation_utils.py` - change import, same interface

### **Step 3: Test & Deploy (5 minutes)**
1. Test OpenRouter still works
2. Test Hugging Face fallback
3. Done!

## ğŸš€ **Benefits - Keep It Simple**

- âœ… **Minimal Changes**: Only change imports in existing files
- âœ… **Two Providers**: OpenRouter + Hugging Face with auto-fallback
- âœ… **Same Interface**: Existing code mostly unchanged
- âœ… **Easy Config**: Change models in one Python file
- âœ… **No Over-Engineering**: 3 files total, not 20+

## ğŸ“‹ **Implementation Checklist**

- [ ] Create `shared/lib/ai/ai_service.py` (main service)
- [ ] Create `config/ai_config.py` (simple config)
- [ ] Create `shared/lib/ai/__init__.py` (exports)
- [ ] Update `ai_utils.py` to use AIService
- [ ] Update `ai_agent.py` to use AIService  
- [ ] Update `video_ai_helpers.py` to use AIService
- [ ] Test both providers work

## ğŸ”§ **Usage Examples**

### **Before (Current)**
```python
# In ai_agent.py - Direct OpenRouter call
response = requests.post(
    'https://openrouter.ai/api/v1/chat/completions',
    headers={'Authorization': f'Bearer {api_key}'},
    json={'model': 'microsoft/phi-3-mini-128k-instruct', ...}
)
```

### **After (Minimalist)**
```python
# Same files, just change the import and one line
from shared.lib.ai import get_ai_service

ai = get_ai_service()

# Simple interface - always defaults to OpenRouter, auto-fallback to Hugging Face
result = ai.call_ai(prompt, task_type='text')           # Text generation
result = ai.call_ai(prompt, task_type='vision', image=img)  # Vision analysis
result = ai.call_ai(prompt, task_type='translation')    # Translation

# No need to specify provider - OpenRouter first, then Hugging Face fallback
```

## ğŸ¯ **Success Metrics**

- âœ… **Minimal Code Changes**: <10 lines changed per file
- âœ… **Two Providers**: OpenRouter + Hugging Face with auto-fallback  
- âœ… **Same Interface**: Existing code works with minimal changes
- âœ… **Simple Config**: One Python file to change all models
- âœ… **No Over-Engineering**: 3 new files total

---

**TLDR: Replace scattered AI calls with one simple service. Same interface, two providers, minimal changes.**
