"""
Ai tool definitions - AUTO-GENERATED (DEBUG VIEW)

‚ö†Ô∏è  DO NOT EDIT THIS FILE MANUALLY!
This file is auto-generated from docstrings in ai_tools.py
To change definitions, update the docstrings in the implementation.

Generated: 2 tools
"""

from typing import List, Dict, Any


def get_tools() -> List[Dict[str, Any]]:
    """
    Auto-generated tool definitions for ai.
    
    üîç DEBUG VIEW: This file shows what was generated from docstrings.
    ‚ö†Ô∏è  Source of truth: ../tools/ai_tools.py docstrings
    """
    return [
    {
        "name": "generate_and_save_testcase",
        "description": "Generate test case graph from prompt AND save it in one step This combines generate_test_graph + save_testcase to avoid the MCP protocol limitation where complex objects can't be passed between tools. \u26a0\ufe0f CRITICAL: Testcase Naming Convention (REQUIRED) - Format: TC_<CATEGORY>_<NUMBER>_<CamelCaseAction> - Category: 3-4 char uppercase code (AUTH, NAV, SRCH, PLAY, PROD, CART, etc.) - Number: 2-digit zero-padded (01-99) - Action: CamelCase descriptor (2-4 words) Examples: - \u2705 TC_AUTH_01_SignupLoginFlow - \u2705 TC_SRCH_01_ProductSearch (note: SRCH not SEARCH) - \u2705 TC_NAV_01_CategoryNavigation - \u2705 TC_CART_01_AddToCart - \u274c TestCase_Auth_1_Signup (wrong format) - \u274c TC_SEARCH_01_Search (should be SRCH) Common Categories: - AUTH: Authentication/signup/login - NAV: Navigation/menus - SRCH: Search functionality - PROD: Product browsing - CART: Shopping cart - PLAY: Video playback - VOD: Video on demand \u26a0\ufe0f CRITICAL: Host/Device Selection - If user explicitly specifies host_name/device_id: Use those values directly - Otherwise: Call get_compatible_hosts(userinterface_name='...') FIRST - DO NOT use default values blindly MCP-formatted response with saved testcase info",
        "inputSchema": {
            "type": "object",
            "properties": {
                "prompt": {
                    "type": "string",
                    "description": "Natural language test description"
                },
                "testcase_name": {
                    "type": "string",
                    "description": "Name following TC_<CAT>_<NUM>_<Action> format"
                }
            },
            "required": [
                "prompt",
                "testcase_name"
            ]
        }
    },
    {
        "name": "generate_test_graph",
        "description": "Generate test case graph from natural language prompt \u26a0\ufe0f CRITICAL: Host/Device Selection - If user explicitly specifies host_name/device_id: Use those values directly - Otherwise: Call get_compatible_hosts(userinterface_name='...') FIRST to find compatible hosts - DO NOT use default values blindly without checking compatibility Uses AI to convert natural language descriptions into executable test graphs. Returns a graph object that can be saved or executed directly. REUSES existing /server/ai/generatePlan endpoint (same as frontend) Pattern from useTestCaseAI.ts line 45 Workflow (when host NOT specified by user): 1. Call get_compatible_hosts(userinterface_name='your_ui') 2. Use recommended host_name and device_id from response 3. Call generate_test_graph with those values Workflow (when user specifies host): 1. User says \"use host X with device Y\" 2. Call generate_test_graph directly with host_name='X', device_id='Y' MCP-formatted response with generated graph JSON, analysis, and stats. Graph can be passed to execute_testcase or save_testcase.",
        "inputSchema": {
            "type": "object",
            "properties": {
                "prompt": {
                    "type": "string",
                    "description": "Natural language test description"
                },
                "current_node_id": {
                    "type": "string",
                    "description": "Starting node for context"
                }
            },
            "required": [
                "prompt"
            ]
        }
    }
]
