# RAM-Based Hot Storage Implementation Plan
## CLEAN ARCHITECTURE - NO LEGACY CODE

**Goal:** Move hot storage (live 100 files + segments) to RAM, keep only archives on SD card

**Primary Benefits:**
- 🔥 **99% reduction in SD card writes** (extends lifespan from months to years)
- ⚡ **10x faster operations** (1ms vs 5ms)
- 🎯 **Zero cache complexity** (no caching needed)
- 💪 **Reduced I/O contention** on SD card

**Trade-off:** Lose last ~50 seconds of data on crash (acceptable for monitoring)

---

## 📁 NEW FOLDER STRUCTURE

### **RAM Storage (tmpfs - ephemeral):**
```
/var/www/html/stream/capture1/hot/     # 100MB tmpfs mount
├── captures/
│   └── capture_*.jpg                   # Last 100 files (~50s)
├── thumbnails/
│   └── capture_*_thumbnail.jpg         # Last 100 files (~20s)
└── segments/
    ├── segment_*.ts                    # Last 10 segments (~10s HLS window)
    └── output.m3u8                     # Live manifest
```

### **SD Card Storage (persistent archive):**
```
/var/www/html/stream/capture1/
├── captures/                           # Archive only (1h retention)
│   ├── 0/                              # Hour 0 (00:00-00:59)
│   ├── 1/                              # Hour 1
│   ├── ...
│   └── 23/                             # Hour 23
├── thumbnails/                         # Archive (24h retention)
│   ├── 0/
│   ├── ...
│   └── 23/
├── metadata/                           # Archive (24h retention)
│   ├── 0/
│   ├── ...
│   └── 23/
└── segments/                           # Archive (24h retention)
    ├── 0/
    │   └── archive.m3u8                # Hour 0 manifest
    ├── ...
    └── 23/
```

**Key Principle:**
- **FFmpeg writes ONLY to RAM** (`hot/` directory)
- **Archival service moves to SD** (when >100 files)
- **Backend reads from RAM for live, SD for history**

---

## 🔧 IMPLEMENTATION TASKS

### **TASK 1: Create RAM Disk Setup Script**

**File:** `backend_host/scripts/setup_ram_hot_storage.sh` (NEW)

```bash
#!/bin/bash
# Setup RAM-based hot storage for all capture devices
# NO LEGACY CODE - Pure RAM implementation

set -e

MOUNT_SIZE="100M"
BASE_PATH="/var/www/html/stream"
DEVICES=("capture1" "capture2" "capture3" "capture4")

echo "================================"
echo "RAM Hot Storage Setup"
echo "================================"

for DEVICE in "${DEVICES[@]}"; do
  HOT_PATH="$BASE_PATH/$DEVICE/hot"
  
  # Create mount point
  echo "Creating mount point: $HOT_PATH"
  mkdir -p "$HOT_PATH"
  
  # Check if already mounted
  if mount | grep -q "$HOT_PATH"; then
    echo "✓ $HOT_PATH already mounted"
  else
    # Mount tmpfs
    echo "Mounting tmpfs ($MOUNT_SIZE) at $HOT_PATH"
    sudo mount -t tmpfs -o size=$MOUNT_SIZE,noexec,nodev,nosuid,uid=sunri-pm,gid=sunri-pm tmpfs "$HOT_PATH"
    echo "✓ Mounted"
  fi
  
  # Create subdirectories
  mkdir -p "$HOT_PATH/captures"
  mkdir -p "$HOT_PATH/thumbnails"
  mkdir -p "$HOT_PATH/segments"
  
  echo "✓ $DEVICE hot storage ready"
  echo ""
done

# Show mounted RAM disks
echo "================================"
echo "Mounted RAM disks:"
df -h | grep "hot"
echo "================================"

# Add to /etc/fstab for persistence (optional, needs manual approval)
echo ""
echo "To make persistent across reboots, add to /etc/fstab:"
echo "---"
for DEVICE in "${DEVICES[@]}"; do
  echo "tmpfs $BASE_PATH/$DEVICE/hot tmpfs size=$MOUNT_SIZE,noexec,nodev,nosuid,uid=sunri-pm,gid=sunri-pm 0 0"
done
echo "---"
```

---

### **TASK 2: Update FFmpeg Script**

**File:** `backend_host/scripts/run_ffmpeg_and_rename_local.sh`

**Changes:**

```bash
#!/bin/bash
# FFmpeg captures to RAM, archives go to SD
# NO LEGACY CODE - Pure RAM hot storage

setup_capture_directories() {
  local capture_dir=$1
  
  # RAM hot storage (tmpfs must be mounted first!)
  local hot_dir="$capture_dir/hot"
  if [ ! -d "$hot_dir" ]; then
    echo "ERROR: Hot storage not mounted at $hot_dir"
    echo "Run setup_ram_hot_storage.sh first!"
    exit 1
  fi
  
  # Create hot subdirectories (RAM)
  mkdir -p "$hot_dir/captures"
  mkdir -p "$hot_dir/thumbnails"
  mkdir -p "$hot_dir/segments"
  
  # Create archive directories (SD card)
  for hour in {0..23}; do
    mkdir -p "$capture_dir/captures/$hour"
    mkdir -p "$capture_dir/thumbnails/$hour"
    mkdir -p "$capture_dir/metadata/$hour"
    mkdir -p "$capture_dir/segments/$hour"
  done
  
  echo "✓ Hot storage (RAM): $hot_dir"
  echo "✓ Archive storage (SD): $capture_dir/{captures,thumbnails,metadata,segments}/0-23"
}

# FFmpeg output paths - WRITE TO RAM ONLY
FFMPEG_CMD="ffmpeg \
  -f v4l2 -input_format mjpeg -video_size 1920x1080 -framerate 30 -i $INPUT_DEVICE \
  -threads 2 -c:v libx264 -preset ultrafast -tune zerolatency -g 30 \
  -sc_threshold 0 -b:v 2M -maxrate 2M -bufsize 4M \
  -vf \"split=3[main][thumb][cap];
       [main]scale=1920:1080[out];
       [thumb]fps=5,scale=320:240[thumb_out];
       [cap]fps=2[cap_out]\" \
  -map '[out]' -f hls -hls_time 1 -hls_list_size 10 -hls_flags delete_segments \
  -hls_segment_filename $CAPTURE_DIR/hot/segments/segment_%09d.ts \
  $CAPTURE_DIR/hot/segments/output.m3u8 \
  -map '[cap_out]' -f image2 -update 1 -strftime 1 \
  $CAPTURE_DIR/hot/captures/capture_%09d.jpg \
  -map '[thumb_out]' -f image2 -update 1 -strftime 1 \
  $CAPTURE_DIR/hot/thumbnails/capture_%09d_thumbnail.jpg"

# Execute
setup_capture_directories "$CAPTURE_DIR"
exec $FFMPEG_CMD
```

**Key Changes:**
- ❌ Removed: Any legacy SD direct writes
- ✅ Added: Hot storage validation (must be mounted)
- ✅ Changed: All FFmpeg outputs go to `hot/` subdirectories

---

### **TASK 3: Create Archival Service**

**File:** `backend_host/scripts/archive_hot_to_cold.py` (NEW)

```python
#!/usr/bin/env python3
"""
RAM Hot → SD Cold Archival Service
CRITICAL SERVICE - Moves files from RAM to SD before they're purged
NO LEGACY CODE - Pure hot/cold architecture
"""
import os
import sys
import time
import shutil
import logging
from datetime import datetime
from pathlib import Path

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[
        logging.FileHandler('/tmp/archive_hot_to_cold.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# Configuration
HOT_LIMIT = 100          # Keep last 100 files in RAM
SEGMENT_LIMIT = 10       # Keep last 10 segments in RAM
ARCHIVE_INTERVAL = 5     # Check every 5 seconds (critical service!)
BASE_PATH = '/var/www/html/stream'
DEVICES = ['capture1', 'capture2', 'capture3', 'capture4']

def get_file_hour(filepath: str) -> int:
    """Get hour (0-23) from file mtime"""
    mtime = os.path.getmtime(filepath)
    return datetime.fromtimestamp(mtime).hour

def archive_files(hot_dir: str, cold_dir: str, pattern: str, limit: int):
    """
    Move old files from RAM hot storage to SD cold storage
    CRITICAL: Must complete before hot storage fills up!
    """
    try:
        # Get files from hot storage (RAM)
        hot_files = sorted(
            [f for f in Path(hot_dir).glob(pattern) if f.is_file()],
            key=lambda f: f.stat().st_mtime
        )
        
        if len(hot_files) <= limit:
            return 0  # Nothing to archive
        
        # Archive oldest files
        files_to_archive = hot_files[:-limit]
        
        logger.info(f"{hot_dir}: Archiving {len(files_to_archive)} files (total: {len(hot_files)})")
        
        archived_count = 0
        for filepath in files_to_archive:
            try:
                # Get destination hour folder on SD
                file_hour = get_file_hour(str(filepath))
                hour_folder = os.path.join(cold_dir, str(file_hour))
                
                # Move from RAM to SD
                dest_path = os.path.join(hour_folder, filepath.name)
                shutil.move(str(filepath), dest_path)
                
                archived_count += 1
                
            except Exception as e:
                logger.error(f"CRITICAL: Failed to archive {filepath}: {e}")
        
        return archived_count
        
    except Exception as e:
        logger.error(f"CRITICAL: Archive failure in {hot_dir}: {e}")
        return 0

def archive_device(device_name: str):
    """Archive all file types for one device"""
    device_path = os.path.join(BASE_PATH, device_name)
    hot_path = os.path.join(device_path, 'hot')
    
    # Validate hot storage is mounted (RAM)
    if not os.path.ismount(hot_path):
        logger.error(f"CRITICAL: {hot_path} is not a tmpfs mount! RAM storage not available!")
        return
    
    total_archived = 0
    
    # Archive captures (full-res images)
    total_archived += archive_files(
        os.path.join(hot_path, 'captures'),
        os.path.join(device_path, 'captures'),
        'capture_*.jpg',
        HOT_LIMIT
    )
    
    # Archive thumbnails
    total_archived += archive_files(
        os.path.join(hot_path, 'thumbnails'),
        os.path.join(device_path, 'thumbnails'),
        'capture_*_thumbnail.jpg',
        HOT_LIMIT
    )
    
    # Archive segments (HLS)
    total_archived += archive_files(
        os.path.join(hot_path, 'segments'),
        os.path.join(device_path, 'segments'),
        'segment_*.ts',
        SEGMENT_LIMIT
    )
    
    if total_archived > 0:
        logger.info(f"✓ {device_name}: Archived {total_archived} files (RAM → SD)")

def main():
    """Main service loop - CRITICAL SERVICE"""
    logger.info("=" * 80)
    logger.info("RAM Hot → SD Cold Archival Service")
    logger.info(f"Hot limits: {HOT_LIMIT} files, {SEGMENT_LIMIT} segments")
    logger.info(f"Interval: {ARCHIVE_INTERVAL}s")
    logger.info("=" * 80)
    
    # Validate all hot storage is mounted
    for device in DEVICES:
        hot_path = os.path.join(BASE_PATH, device, 'hot')
        if not os.path.ismount(hot_path):
            logger.error(f"CRITICAL: {hot_path} not mounted! Run setup_ram_hot_storage.sh first!")
            sys.exit(1)
    
    logger.info("✓ All RAM hot storage validated")
    
    while True:
        try:
            start_time = time.time()
            
            for device in DEVICES:
                archive_device(device)
            
            elapsed = time.time() - start_time
            logger.debug(f"Archive cycle completed ({elapsed:.2f}s)")
            
            time.sleep(ARCHIVE_INTERVAL)
            
        except KeyboardInterrupt:
            logger.info("Shutting down...")
            break
        except Exception as e:
            logger.error(f"CRITICAL: Archive service error: {e}")
            time.sleep(10)  # Wait before retry

if __name__ == '__main__':
    main()
```

**Key Features:**
- ❌ No legacy/fallback code
- ✅ Validates RAM mount on startup
- ✅ Fast 5-second cycle (critical service)
- ✅ Detailed logging for monitoring

---

### **TASK 4: Create Systemd Service**

**File:** `backend_host/systemd/archive_hot_to_cold.service` (NEW)

```ini
[Unit]
Description=RAM Hot to SD Cold Archival Service (CRITICAL)
After=network.target local-fs.target
Requires=local-fs.target
# CRITICAL: Must run for system to function properly

[Service]
Type=simple
User=sunri-pm
WorkingDirectory=/home/sunri-pm/virtualpytest/backend_host
ExecStart=/home/sunri-pm/virtualpytest/venv/bin/python3 /home/sunri-pm/virtualpytest/backend_host/scripts/archive_hot_to_cold.py

# Restart aggressively - this is critical
Restart=always
RestartSec=5

# Resource limits
MemoryLimit=100M
CPUQuota=25%

# Logging
StandardOutput=journal
StandardError=journal
SyslogIdentifier=archive-hot-cold

# Monitoring
WatchdogSec=30

[Install]
WantedBy=multi-user.target
```

---

### **TASK 5: Update Cleanup Script**

**File:** `backend_host/scripts/clean_captures.sh`

**Changes:**

```bash
#!/bin/bash
# Clean SD archive hour folders only
# NO LEGACY CODE - Never touch RAM hot storage

CLEAN_LOG="/tmp/clean.log"
> "$CLEAN_LOG"

BASE_PATH="/var/www/html/stream"
DEVICES=("capture1" "capture2" "capture3" "capture4")
CURRENT_HOUR=$(date +%-H)
CUTOFF_HOUR=$(( (CURRENT_HOUR + 1) % 24 ))

echo "$(date): Starting cleanup (delete hour $CUTOFF_HOUR)" >> "$CLEAN_LOG"

for DEVICE in "${DEVICES[@]}"; do
  DEVICE_PATH="$BASE_PATH/$DEVICE"
  
  if [ ! -d "$DEVICE_PATH" ]; then
    continue
  fi
  
  echo "$(date): Cleaning $DEVICE" >> "$CLEAN_LOG"
  
  # Clean captures (1h retention)
  if [ -d "$DEVICE_PATH/captures/$CUTOFF_HOUR" ]; then
    rm -rf "$DEVICE_PATH/captures/$CUTOFF_HOUR"
    mkdir -p "$DEVICE_PATH/captures/$CUTOFF_HOUR"
    echo "  ✓ Deleted captures/$CUTOFF_HOUR" >> "$CLEAN_LOG"
  fi
  
  # Clean thumbnails (24h retention)
  if [ -d "$DEVICE_PATH/thumbnails/$CUTOFF_HOUR" ]; then
    rm -rf "$DEVICE_PATH/thumbnails/$CUTOFF_HOUR"
    mkdir -p "$DEVICE_PATH/thumbnails/$CUTOFF_HOUR"
    echo "  ✓ Deleted thumbnails/$CUTOFF_HOUR" >> "$CLEAN_LOG"
  fi
  
  # Clean metadata (24h retention)
  if [ -d "$DEVICE_PATH/metadata/$CUTOFF_HOUR" ]; then
    rm -rf "$DEVICE_PATH/metadata/$CUTOFF_HOUR"
    mkdir -p "$DEVICE_PATH/metadata/$CUTOFF_HOUR"
    echo "  ✓ Deleted metadata/$CUTOFF_HOUR" >> "$CLEAN_LOG"
  fi
  
  # Clean segments (24h retention)
  if [ -d "$DEVICE_PATH/segments/$CUTOFF_HOUR" ]; then
    rm -rf "$DEVICE_PATH/segments/$CUTOFF_HOUR"
    mkdir -p "$DEVICE_PATH/segments/$CUTOFF_HOUR"
    echo "  ✓ Deleted segments/$CUTOFF_HOUR" >> "$CLEAN_LOG"
  fi
  
  # NEVER touch hot/ - it's in RAM!
done

echo "$(date): Cleanup complete" >> "$CLEAN_LOG"
```

**Key Changes:**
- ❌ Removed: All legacy SD hot storage cleanup
- ✅ Added: Comment to never touch RAM hot/
- ✅ Simplified: Only deletes hour folders

---

### **TASK 6: Update Backend Screenshot API**

**File:** `backend_host/src/controllers/base_controller.py` (or similar)

**Changes:**

```python
def take_screenshot(self, filename: str = None) -> Optional[str]:
    """
    Take screenshot from RAM hot storage
    FAST: <1ms (max 100 files in RAM)
    NO LEGACY CODE
    """
    try:
        import time
        import os
        from pathlib import Path
        
        # RAM hot storage path
        hot_captures = f"{self.video_capture_path}/hot/captures"
        
        # Validate hot storage exists
        if not os.path.exists(hot_captures):
            logger.error(f"[{self.capture_source}]: Hot storage not found: {hot_captures}")
            return None
        
        # Get latest from RAM (max 100 files)
        jpg_files = sorted(
            Path(hot_captures).glob('capture_*.jpg'),
            key=lambda f: f.stat().st_mtime,
            reverse=True
        )
        
        if not jpg_files:
            logger.warning(f"[{self.capture_source}]: No images in hot storage")
            return None
        
        latest_jpg = str(jpg_files[0])
        age = time.time() - os.path.getmtime(latest_jpg)
        
        if age > 3:
            logger.warning(f"[{self.capture_source}]: Latest image too old: {age:.2f}s")
            return None
        
        logger.info(f"[{self.capture_source}]: Screenshot from RAM (age: {age:.2f}s)")
        return latest_jpg
        
    except Exception as e:
        logger.error(f'[{self.capture_source}]: Screenshot error: {e}')
        return None
```

**Key Changes:**
- ❌ Removed: Legacy SD hot storage paths
- ✅ Changed: Read from `/hot/captures/` (RAM)
- ✅ Added: Hot storage validation

---

### **TASK 7: Create Archive API Endpoints**

**File:** `backend_host/src/routes/host_monitoring_routes.py` (or new file)

```python
@host_monitoring_bp.route('/api/host/thumbnails/<device_name>/<int:hour>', methods=['GET'])
def get_thumbnails_for_hour(device_name: str, hour: int):
    """
    Get archived thumbnails for specific hour (from SD)
    Used by heatmap to display 24h view
    """
    try:
        if hour < 0 or hour > 23:
            return jsonify({'error': 'Invalid hour (0-23)'}), 400
        
        # SD archive path
        thumbnails_dir = f'/var/www/html/stream/{device_name}/thumbnails/{hour}'
        
        if not os.path.exists(thumbnails_dir):
            return jsonify({'hour': hour, 'count': 0, 'thumbnails': []})
        
        # Get all thumbnails from archive
        thumbnails = sorted(
            Path(thumbnails_dir).glob('capture_*_thumbnail.jpg'),
            key=lambda f: int(f.stem.split('_')[1])
        )
        
        # Build URLs
        thumbnail_urls = [
            f'/host/stream/{device_name}/thumbnails/{hour}/{thumb.name}'
            for thumb in thumbnails
        ]
        
        return jsonify({
            'hour': hour,
            'count': len(thumbnail_urls),
            'thumbnails': thumbnail_urls
        })
        
    except Exception as e:
        logger.error(f"Error getting thumbnails: {e}")
        return jsonify({'error': str(e)}), 500


@host_monitoring_bp.route('/api/host/segments/<device_name>/<int:hour>', methods=['GET'])
def get_segments_manifest(device_name: str, hour: int):
    """
    Get HLS manifest for archived hour (from SD)
    Used for archive video playback
    """
    try:
        if hour < 0 or hour > 23:
            return jsonify({'error': 'Invalid hour (0-23)'}), 400
        
        # SD archive manifest
        manifest_path = f'/var/www/html/stream/{device_name}/segments/{hour}/archive.m3u8'
        
        if not os.path.exists(manifest_path):
            return jsonify({'error': 'Manifest not found'}), 404
        
        # Return manifest URL
        return jsonify({
            'hour': hour,
            'manifest_url': f'/host/stream/{device_name}/segments/{hour}/archive.m3u8'
        })
        
    except Exception as e:
        logger.error(f"Error getting manifest: {e}")
        return jsonify({'error': str(e)}), 500
```

---

### **TASK 8: Update Frontend**

**File:** `frontend/src/hooks/monitoring/useMonitoring.ts` (or similar)

**Changes:**

```typescript
// Load 24h heatmap from SD archives
async function loadHeatmap(deviceName: string) {
  const hours = Array.from({length: 24}, (_, i) => i);
  
  // Load each hour from SD archive
  const hourlyData = await Promise.all(
    hours.map(hour => 
      fetch(`/api/host/thumbnails/${deviceName}/${hour}`)
        .then(r => r.json())
        .catch(() => ({ hour, count: 0, thumbnails: [] }))
    )
  );
  
  // Combine into 24h view
  return hourlyData.flatMap(data => data.thumbnails);
}

// Play archived video from SD
async function playArchiveVideo(deviceName: string, hour: number) {
  const response = await fetch(`/api/host/segments/${deviceName}/${hour}`);
  const { manifest_url } = await response.json();
  
  // Load in HLS player
  player.loadSource(manifest_url);
  player.play();
}
```

---

### **TASK 9: Delete ALL Cache Code**

**Files to DELETE completely (NO legacy code):**

```bash
# Find and delete all cache-related files
backend_host/src/services/cache/tier1_cache.py          # DELETE
backend_host/src/services/cache/tier2_cache.py          # DELETE
backend_host/src/services/cache/tier3_cache.py          # DELETE
backend_host/src/services/cache/cache_manager.py        # DELETE
backend_host/systemd/tier1_cache.service                # DELETE
backend_host/systemd/tier2_cache.service                # DELETE
backend_host/systemd/tier3_cache.service                # DELETE
```

**Remove cache imports from:**
- `backend_host/src/controllers/*.py` - Remove all cache imports/calls
- `backend_host/src/services/*.py` - Remove all cache dependencies
- `backend_host/src/routes/*.py` - Remove cache endpoints

**Result:** ~2,000 lines of cache code DELETED

---

### **TASK 10: Create Health Monitoring**

**File:** `backend_host/scripts/monitor_hot_storage.py` (NEW)

```python
#!/usr/bin/env python3
"""
Monitor RAM hot storage health
Alerts if:
- Hot storage not mounted
- Archival service not running
- Hot storage filling up (>90 files)
"""
import os
import subprocess
from pathlib import Path

BASE_PATH = '/var/www/html/stream'
DEVICES = ['capture1', 'capture2', 'capture3', 'capture4']

def check_hot_storage():
    """Check all hot storage mounts"""
    issues = []
    
    for device in DEVICES:
        hot_path = os.path.join(BASE_PATH, device, 'hot')
        
        # Check mount
        if not os.path.ismount(hot_path):
            issues.append(f"❌ {device}: Hot storage not mounted!")
        
        # Check file counts
        for subdir in ['captures', 'thumbnails', 'segments']:
            full_path = os.path.join(hot_path, subdir)
            if os.path.exists(full_path):
                count = len(list(Path(full_path).glob('*')))
                limit = 10 if subdir == 'segments' else 100
                
                if count > limit * 0.9:
                    issues.append(f"⚠️  {device}/{subdir}: {count}/{limit} files (archival may be slow!)")
    
    return issues

def check_archival_service():
    """Check archival service status"""
    result = subprocess.run(
        ['systemctl', 'is-active', 'archive_hot_to_cold'],
        capture_output=True,
        text=True
    )
    
    if result.stdout.strip() != 'active':
        return "❌ CRITICAL: Archival service not running!"
    
    return None

if __name__ == '__main__':
    print("=" * 50)
    print("RAM Hot Storage Health Check")
    print("=" * 50)
    
    # Check mounts and file counts
    issues = check_hot_storage()
    
    # Check archival service
    service_issue = check_archival_service()
    if service_issue:
        issues.append(service_issue)
    
    if issues:
        print("\n".join(issues))
        exit(1)
    else:
        print("✅ All checks passed")
        exit(0)
```

---

## 📋 DEPLOYMENT SEQUENCE

### **Step 1: Setup (Non-breaking)**
1. Run `setup_ram_hot_storage.sh` to create RAM mounts
2. Add to `/etc/fstab` for persistence
3. Reboot and verify mounts

### **Step 2: Deploy Archival Service**
1. Copy `archive_hot_to_cold.py` to scripts/
2. Copy `archive_hot_to_cold.service` to systemd/
3. Enable and start service
4. Monitor logs: `journalctl -u archive_hot_to_cold -f`

### **Step 3: Update FFmpeg**
1. Stop FFmpeg processes
2. Update `run_ffmpeg_and_rename_local.sh`
3. Restart FFmpeg
4. Verify writes going to `/hot/` directories

### **Step 4: Update Backend**
1. Update screenshot API to read from `/hot/`
2. Add archive API endpoints
3. Deploy backend
4. Test APIs

### **Step 5: Update Frontend**
1. Update to use hour-based APIs
2. Test heatmap and archive playback
3. Deploy frontend

### **Step 6: Delete Cache Code**
1. Delete ALL cache files (TIER 1, 2, 3)
2. Remove cache imports from controllers
3. Remove cache systemd services
4. Deploy clean codebase

### **Step 7: Update Cleanup**
1. Update `clean_captures.sh`
2. Update cron job
3. Test cleanup (should be instant)

### **Step 8: Monitoring**
1. Deploy `monitor_hot_storage.py`
2. Add to cron for periodic checks
3. Setup alerts if failures

---

## ✅ VALIDATION CHECKLIST

- [ ] RAM mounts created and persistent (`df -h | grep hot`)
- [ ] Archival service running (`systemctl status archive_hot_to_cold`)
- [ ] FFmpeg writing to `/hot/` directories
- [ ] Files archiving to SD hour folders within 5s
- [ ] Hot storage stays under 100 files
- [ ] Screenshot API returns <1ms (from RAM)
- [ ] Heatmap loads from SD archives
- [ ] Archive video playback works
- [ ] Cleanup deletes hour folders instantly
- [ ] ALL cache code deleted (0 cache files remaining)
- [ ] Health monitoring alerts work
- [ ] SD card writes reduced by 99%

---

## 🎯 EXPECTED RESULTS

**Performance:**
- Screenshot: 5ms → <1ms (5x faster)
- FFmpeg writes: 10ms → 0.1ms (100x faster)
- Cleanup: 5-10s → <1ms (1000x faster)

**Reliability:**
- SD card lifespan: months → years (99% write reduction)
- I/O contention: eliminated
- Failure mode: lose <60s on crash (acceptable)

**Complexity:**
- Cache services: 3 → 0
- Code: ~2,000 lines deleted
- Architecture: Simple hot (RAM) + cold (SD)

**Storage:**
- RAM usage: 300MB (4 devices × 75MB)
- SD writes: 600k/day → 6k/day (99% reduction)

---

## 🚨 CRITICAL NOTES

1. **Archival service is CRITICAL** - If it fails, RAM fills up and FFmpeg crashes
2. **Monitor archival logs** - Must complete cycles within 5 seconds
3. **No data loss tolerance** - Files must be archived before RAM purge
4. **Boot sequence matters** - RAM mounts must exist before FFmpeg starts
5. **NO LEGACY CODE** - Clean implementation, no fallbacks

---

**Ready to implement! Start with TODO #1.**

